{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "Strunturally constrained recurrent network(SCRN)\n",
    "Goal is to predict the next token in the sequence given its past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import package\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time as time\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data import parameter\n",
    "#filename_input = \"words.txt\"\n",
    "filename_input = \"words_total.txt\"\n",
    "eval_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN parameter\n",
    "input_size = 26 # one-hot input of characters\n",
    "s_size = 10 # size of context layer(slow)\n",
    "h_size = 40 # size of hidden layer(fast)\n",
    "output_size = 26 # output size, one-hot output of character\n",
    "alpha = 0.95 # 0.95\n",
    "num_fw = 5 # forward steps\n",
    "num_bp = 50 # 50 BPTT steps\n",
    "lr = 2.5 # initial learning rate\n",
    "batch_size = 32\n",
    "Epochs = 6000 # number of epochs\n",
    "per_epoch = 100 # epochs to display loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import file: words_total.txt\n"
     ]
    }
   ],
   "source": [
    "# import data from dataset, articles or reviews\n",
    "with open(filename_input) as file_input:\n",
    "    data_str = file_input.read()\n",
    "print('Import file: '+filename_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = int((len(data_str)-num_fw)/num_bp/batch_size)\n",
    "data_mat = np.asarray([ord(char)-ord('a') for char in data_str])\n",
    "\n",
    "train_data_len = int((steps-eval_steps)*num_bp*batch_size)\n",
    "eval_data_len = int(eval_steps*num_bp*batch_size)\n",
    "\n",
    "train_data_mat = np.zeros([train_data_len, num_fw])\n",
    "train_data_y = np.zeros([train_data_len])\n",
    "eval_data_x = np.zeros([eval_data_len, num_fw])\n",
    "eval_data_y = np.zeros([eval_data_len])\n",
    "train_data_x = list()\n",
    "train_data_y = list()\n",
    "eval_data_x = list()\n",
    "eval_data_y = list()\n",
    "\n",
    "for ii in range(train_data_len):\n",
    "    train_data_x.append(data_mat[ii:ii+num_fw])\n",
    "    train_data_y.append(data_mat[ii+num_fw])\n",
    "for ii in range(eval_data_len):\n",
    "    jj = ii + train_data_len\n",
    "    eval_data_x.append(data_mat[jj:jj+num_fw])\n",
    "    eval_data_y.append(data_mat[jj+num_fw])\n",
    "\n",
    "train_data_batchx = list()\n",
    "train_data_batchy = list()\n",
    "per_batch = int((steps-eval_steps)*num_bp)\n",
    "for i in range(batch_size):\n",
    "    train_data_batchx.append(train_data_x[i*per_batch: (i+1)*per_batch])\n",
    "    train_data_batchy.append(train_data_y[i*per_batch: (i+1)*per_batch])\n",
    "\n",
    "train_data_batchx = np.asarray(train_data_batchx)\n",
    "train_data_batchy = np.asarray(train_data_batchy)\n",
    "train_data_stepx = list()\n",
    "train_data_stepy = list()\n",
    "for i in range(int(steps-eval_steps)):\n",
    "    train_data_stepx.append(train_data_batchx[:, i*num_bp:(i+1)*num_bp, :])\n",
    "    train_data_stepy.append(train_data_batchy[:, i*num_bp:(i+1)*num_bp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11 steps, 32 batches, 10 bps, 5 fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define structure of SCRN\n",
    "trainX = list()\n",
    "trainY = list()\n",
    "for i in range(num_fw + num_bp):\n",
    "    trainX.append(tf.placeholder(tf.float32, shape=(batch_size, input_size)))\n",
    "for i in range(num_bp):\n",
    "    trainY.append(tf.placeholder(tf.float32, shape=(batch_size, output_size)))\n",
    "    \n",
    "s_first = tf.placeholder(tf.float32, shape=(batch_size, s_size), name='1st_s')\n",
    "h_first = tf.placeholder(tf.float32, shape=(batch_size, h_size), name='1st_h')\n",
    "\n",
    "diag_I = np.ones([s_size]).astype('float32')\n",
    "diag_Q = alpha*np.ones([s_size]).astype('float32')\n",
    "I = tf.diag(diag_I, name=\"I\")\n",
    "Q = tf.diag(diag_Q, name=\"Q\")\n",
    "B = tf.Variable(tf.truncated_normal([input_size, s_size], -0.1,0.1), name='B')\n",
    "\n",
    "P = tf.Variable(tf.truncated_normal([s_size, h_size], -0.1,0.1), name='P')\n",
    "A = tf.Variable(tf.truncated_normal([input_size, h_size], -0.1,0.1), name='A')\n",
    "R = tf.Variable(tf.truncated_normal([h_size, h_size], -0.1,0.1), name='R')\n",
    "\n",
    "U = tf.Variable(tf.truncated_normal([h_size, output_size], -0.1,0.1), name='U')\n",
    "V = tf.Variable(tf.truncated_normal([s_size, output_size], -0.1,0.1), name='V')\n",
    "\n",
    "\n",
    "def SCRN(x, s_pre, h_pre):\n",
    "    s_after = tf.matmul(x, tf.matmul(B, (I-Q))) + tf.matmul(s_pre, Q) # s_t = (I-Q)Bx_t + Qs_t-1\n",
    "    h_after = tf.sigmoid(tf.matmul(s_after, P)+tf.matmul(x, A)+tf.matmul(h_pre,R)) #h_t = sigmoid(Ps_t+Ax_t+Rh_t-1)\n",
    "    y_after = tf.nn.softmax(tf.matmul(h_after, U)+tf.matmul(s_after, V)) #y_t = f(Uh_t + Vs_t)\n",
    "    \n",
    "    return s_after, h_after, y_after\n",
    "\n",
    "\n",
    "# forward\n",
    "for i in range(num_bp):\n",
    "    j = 0\n",
    "    if i == 0:\n",
    "        outputs = list()\n",
    "        s_pre = s_first\n",
    "        h_pre = h_first\n",
    "    \n",
    "    for j in range(num_fw):\n",
    "        if j<num_fw-1:\n",
    "            s_after, h_after, _ = SCRN(trainX[i+j], s_pre, h_pre)\n",
    "        else:\n",
    "            s_after, h_after,y_after = SCRN(trainX[i+j], s_pre, h_pre)\n",
    "        \n",
    "        \n",
    "        #dropout\n",
    "        s_after = tf.nn.dropout(s_after, keep_prob=0.8)\n",
    "        h_after = tf.nn.dropout(h_after, keep_prob=0.9)\n",
    "        \n",
    "        \n",
    "        s_pre = s_after\n",
    "        h_pre = h_after\n",
    "    \n",
    "    \n",
    "    outputs.append(y_after)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train opt\n",
    "\n",
    "#log likelihood loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=tf.concat(outputs,0),labels=tf.concat(trainY,0)))\n",
    "#loss = tf.losses.mean_squared_error(labels=tf.concat(trainY,0), predictions = tf.concat(outputs,0))\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "#optimizer\n",
    "global_epoch = tf.Variable(0)\n",
    "#learning_rate = tf.train.exponential_decay(\n",
    "#    learning_rate=, global_step=global_epoch, decay_steps=5000, decay_rate=0.9, staircase=True)\n",
    "#learning_rate = lr\n",
    "\n",
    "#optimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.5, use_nesterov=True)\n",
    "\n",
    "\n",
    "gradients,var=zip(*optimizer.compute_gradients(loss))\n",
    "gradients_clipped, _ = tf.clip_by_global_norm(gradients, 0.1)\n",
    "opt=optimizer.apply_gradients(zip(gradients_clipped,var),global_step=global_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add init op to the graph\n",
    "init = tf.global_variables_initializer()\n",
    "steps = len(train_data_stepy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#init parameters\n",
    "d_loss = 1.0\n",
    "lr_ = lr\n",
    "outputs_series = list()\n",
    "average_loss_series = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60ac357b62b4bcebca6adc8ea8239bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Average Loss: 3.12016320229 Learning Rate: 0.7407407407407408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lixiang\\Anaconda3\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\lixiang\\src\\tqdm\\tqdm\\_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\Lixiang\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 Average Loss: 3.1179921627 Learning Rate: 0.7407407407407408\n",
      "Epoch: 200 Average Loss: 3.11793518066 Learning Rate: 0.4938271604938272\n",
      "Epoch: 300 Average Loss: 3.11956453323 Learning Rate: 0.4938271604938272\n",
      "Epoch: 400 Average Loss: 3.11596703529 Learning Rate: 0.4938271604938272\n",
      "Epoch: 500 Average Loss: 3.11708426476 Learning Rate: 0.4938271604938272\n",
      "Epoch: 600 Average Loss: 3.11567378044 Learning Rate: 0.4938271604938272\n",
      "Epoch: 700 Average Loss: 3.11223363876 Learning Rate: 0.4938271604938272\n",
      "Epoch: 800 Average Loss: 3.11515450478 Learning Rate: 0.4938271604938272\n",
      "Epoch: 900 Average Loss: 3.11761927605 Learning Rate: 0.4938271604938272\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-39a93f000e2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m#feed_dict[learning_rate] = 0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mh_after_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_after_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0moutputs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh_after\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_after\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0moutputs_series\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0maverage_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train SCRN\n",
    "#lr_ = 0.1\n",
    "#per_epoch = 100\n",
    "#global_epoch = tf.Variable(0)\n",
    "#Epochs = 30000\n",
    "pbar = tqdm(range(Epochs))\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    feed_dict = {}\n",
    "    feed_dict[learning_rate] = lr_\n",
    "    \n",
    "    for step in range(steps):\n",
    "\n",
    "        average_loss = list()\n",
    "        #initialize the output\n",
    "        if step == 0:\n",
    "            \n",
    "            if epoch == 0:\n",
    "                h_pass = np.zeros([batch_size, h_size], dtype=np.float32)\n",
    "                s_pass = np.zeros([batch_size, s_size], dtype=np.float32)\n",
    "            else:\n",
    "                h_pass = np.zeros([batch_size, h_size], dtype=np.float32)\n",
    "                h_pass[1:batch_size,:] = np.asarray(h_after_[0:batch_size-1,:])\n",
    "                s_pass = np.zeros([batch_size, s_size], dtype=np.float32)\n",
    "                s_pass[1:batch_size,:] = np.asarray(s_after_[0:batch_size-1,:])\n",
    "                \n",
    "            h_pass = np.zeros([batch_size, h_size], dtype=np.float32)\n",
    "            s_pass = np.zeros([batch_size, s_size], dtype=np.float32)\n",
    "        else:\n",
    "            h_pass = h_after_\n",
    "            s_pass = s_after_\n",
    "        #feed_dict={h_first: h_pass, s_first:s_pass}\n",
    "        feed_dict[h_first] = h_pass\n",
    "        feed_dict[s_first] = s_pass\n",
    "\n",
    "#11 steps, 32 batches, 10 bp, 5 fw\n",
    "        #trains x\n",
    "        for i in range(num_bp+num_fw):\n",
    "            if i <num_bp-1:\n",
    "                batch_x_i = train_data_stepx[step][:,i,0].astype(int)\n",
    "            else:\n",
    "                batch_x_i = train_data_stepx[step][:,num_bp-1,i-num_bp].astype(int)\n",
    "            batch_x_i.reshape([batch_size,1])\n",
    "            batch_x_i_onehot = np.zeros((len(batch_x_i), input_size))\n",
    "            batch_x_i_onehot[range(len(batch_x_i)), batch_x_i] = 1\n",
    "            feed_dict[trainX[i]] = batch_x_i_onehot\n",
    "            \n",
    "        for i in range(num_bp):\n",
    "            batch_y_i = train_data_stepy[step][:,i].astype(int)\n",
    "            batch_y_i.reshape([batch_size,1])\n",
    "            batch_y_i_onehot = np.zeros((len(batch_y_i), output_size))\n",
    "            batch_y_i_onehot[range(len(batch_y_i)), batch_y_i]=1\n",
    "            feed_dict[trainY[i]] = batch_y_i_onehot\n",
    "\n",
    "        #feed_dict[learning_rate] = 0.1\n",
    "\n",
    "        h_after_, s_after_, l ,outputs_, opt_ = sess.run([h_after, s_after, loss, outputs, opt], feed_dict=feed_dict)\n",
    "        outputs_series.append(outputs_)\n",
    "        average_loss.append(l)\n",
    "        ave_loss = sum(average_loss)/float(len(average_loss))\n",
    "\n",
    "        \n",
    "    pbar.update(1)\n",
    "\n",
    "    #average_loss_series.append(ave_loss)\n",
    "    global_epoch += 1\n",
    "    if epoch%per_epoch == 0:\n",
    "        average_loss_series.append(ave_loss)\n",
    "        \n",
    "        if len(average_loss_series) == 1:\n",
    "            d_loss = average_loss_series[0]\n",
    "            ave_loss_pre = ave_loss\n",
    "        else:\n",
    "            #d_loss = average_loss_series[-1] - average_loss_series[-2]\n",
    "            d_loss = ave_loss_pre - ave_loss\n",
    "            ave_loss_pre = ave_loss\n",
    "        \n",
    "        \n",
    "        if np.abs(d_loss)<1.0e-3:\n",
    "            lr_ = lr_/1.5\n",
    "        \n",
    "        \n",
    "        print('Epoch: '+str(epoch)+ ' Average Loss: ' +str(ave_loss) + ' Learning Rate: ' +str(lr_))\n",
    "    #if ave_loss<0.8:\n",
    "    #    break\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x156b5676e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot tuning curve\n",
    "f1 = plt.figure()\n",
    "plt.plot(average_loss_series)\n",
    "plt.show(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict and evaluate\n",
    "def eval_(data_x=eval_data_x, data_y=eval_data_y, num_fw=num_fw):\n",
    "    evalX=[]\n",
    "    y_ = []\n",
    "    char_= list()\n",
    "    for ii in range(num_fw):\n",
    "        evalX.append(tf.placeholder(tf.float32, shape=(1, input_size)))\n",
    "    \n",
    "    s_first_eval = tf.placeholder(tf.float32, shape=(1, s_size), name='1st_s_eval')\n",
    "    h_first_eval = tf.placeholder(tf.float32, shape=(1, h_size), name='1st_h_eval')\n",
    "    \n",
    "    for j in range(num_fw):\n",
    "        if j<num_fw-1:\n",
    "            s_after_eval, h_after_eval, _ = SCRN(evalX[j], s_first_eval, h_first_eval)\n",
    "        else:\n",
    "            s_after_eval, h_after_eval,y_after_eval = SCRN(evalX[j], s_pre_eval, h_pre_eval)\n",
    "        s_pre_eval = s_after_eval\n",
    "        h_pre_eval = h_after_eval\n",
    "    outputs_eval = tf.argmax(y_after_eval)\n",
    "    \n",
    "    acc_eva = 0\n",
    "    for step in range(len(data_y)):\n",
    "        #feed dictory\n",
    "        if step == 0:\n",
    "            h_pass_eval = np.zeros([1, h_size], dtype=np.float32)\n",
    "            s_pass_eval = np.zeros([1, s_size], dtype=np.float32)\n",
    "        else:\n",
    "            h_pass_eval = h_after_eval_\n",
    "            s_pass_eval = s_after_eval_\n",
    "        feed_dict_eval={h_first_eval: h_pass_eval, s_first_eval:s_pass_eval}\n",
    "        for ii in range(num_fw):\n",
    "            data_x_i = data_x[step][ii].reshape([1])\n",
    "            data_x_i_onehot = np.zeros([1,input_size])\n",
    "            #print(step, ii, data_x_i)\n",
    "            data_x_i_onehot[range(1),data_x_i] = 1\n",
    "            feed_dict_eval[evalX[ii]] = data_x_i_onehot\n",
    "            \n",
    "        h_after_eval_, s_after_eval_, outputs_eval_, y_after_eval_= sess.run(\n",
    "            [h_after_eval, s_after_eval, outputs_eval, y_after_eval], feed_dict=feed_dict_eval)\n",
    "        \n",
    "        y_.append(chr(np.argmax(y_after_eval_)+ord('a')))\n",
    "        \n",
    "        if np.argmax(y_after_eval_) == data_y[step].reshape([]):\n",
    "            acc_eva += 1\n",
    "            #print(y_[-1],chr(data_y[step]+ord('a')))\n",
    "            char_.append(y_[-1])\n",
    "    \n",
    "    print('List of successfully recalled characters: %s' %(list(set(char_))))\n",
    "    acc = acc_eva/len(data_y)\n",
    "    print('Accuracy: %f'%(acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of successfully recalled characters: ['o', 't', 'e', 'r']\n",
      "Accuracy: 0.200937\n"
     ]
    }
   ],
   "source": [
    "acc =eval_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results(generate a paper? recall the memory?)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
